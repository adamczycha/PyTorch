{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class train_MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        train_xy = np.loadtxt('C:/Users/Marcel/Documents/PyTorch/kaggle/digit_recognizer/train.csv', delimiter=',',dtype=np.float32, skiprows=1) \n",
    "        self.train_x = torch.from_numpy(train_xy[:,1:])\n",
    "        self.train_y = torch.from_numpy(train_xy[:,0]).long()\n",
    "        self.n_samples = train_xy.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        x = self.train_x[index].view(1, 28, 28)\n",
    "        y = self.train_y[index]\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "class test_MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        train_x = np.loadtxt('C:/Users/Marcel/Documents/PyTorch/kaggle/digit_recognizer/test.csv', delimiter=',',dtype=np.float32, skiprows=1) \n",
    "        self.train_x = torch.from_numpy(train_x)\n",
    "        self.n_samples = train_x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        x = self.train_x[index].view(1, 28, 28)\n",
    "        return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = train_MnistDataset()\n",
    "dataset_test = test_MnistDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes.iter as pipes\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "#Training performance\n",
    "train_size, test_size = int(len(dataset) * 0.8), len(dataset) - (int(len(dataset) * 0.8))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_train, batch_test =  100, 100\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_train, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_test)\n",
    "\n",
    "\n",
    "# Used for submition \n",
    "kaggle_train_dataloader = DataLoader(dataset, batch_size= batch_train, shuffle=True)\n",
    "kaggle_test_dataloader = DataLoader(dataset_test, batch_size= len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 192,kernel_size=3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(192, 192 ,kernel_size=5,padding=2)\n",
    "\n",
    "\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x) \n",
    "        x = F.max_pool2d(x,2, padding=1)\n",
    "        x = x.flatten(1)   \n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.shape[1], 256)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer_in):\n",
    "    if isinstance(layer_in, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(layer_in.weight)\n",
    "        layer_in.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Store resultsn   n  \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataset), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle used as flag to remove statistics\n",
    "def test(dataloader, predictions = None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        if predictions == None:\n",
    "            for data, target in dataloader:\n",
    "                output = model(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        else:       \n",
    "            for data in dataloader:\n",
    "                output = model(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                predictions.append(pred)\n",
    "                \n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    if predictions == None:\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataloader.dataset),\n",
    "            100. * correct / len(dataloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def kaggle_test(predictions):\n",
    "#     model.eval()\n",
    "#     test_loss = 0\n",
    "#     correct = 0\n",
    "#     with torch.no_grad():\n",
    "#         for data in kaggle_dataloader:\n",
    "#             output = model(data)\n",
    "#             pred = output.data.max(1, keepdim=True)[1]\n",
    "            \n",
    "#             predictions.append(pred)\n",
    "#     test_loss /= len(kaggle_dataloader.dataset)\n",
    "#     print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "#         test_loss, correct, len(kaggle_dataloader.dataset),\n",
    "#         100. * correct / len(kaggle_dataloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Marcel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\nn\\_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.4190, Accuracy: 974/8400 (12%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/42000]\tLoss: 0.044448\n",
      "Train Epoch: 1 [1000/42000]\tLoss: 0.023661\n",
      "Train Epoch: 1 [2000/42000]\tLoss: 0.126045\n",
      "Train Epoch: 1 [3000/42000]\tLoss: 0.130805\n",
      "Train Epoch: 1 [4000/42000]\tLoss: 0.169722\n",
      "Train Epoch: 1 [5000/42000]\tLoss: 0.148961\n",
      "Train Epoch: 1 [6000/42000]\tLoss: 0.042026\n",
      "Train Epoch: 1 [7000/42000]\tLoss: 0.181557\n",
      "Train Epoch: 1 [8000/42000]\tLoss: 0.045725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch, kaggle_train_dataloader)\n",
    "  # testing on the same data to get more info in the model\n",
    "  test(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test(kaggle_test_dataloader,predictions)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "indexes = range(1,len(predictions)+1,1)\n",
    "df = pd.DataFrame({'ImageId': indexes, 'Label': predictions} )\n",
    "df.to_csv('kaggle_sub_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
