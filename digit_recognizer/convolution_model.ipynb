{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class train_MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        train_xy = np.loadtxt('C:/Users/Marcel/Documents/PyTorch/kaggle/digit_recognizer/train.csv', delimiter=',',dtype=np.float32, skiprows=1) \n",
    "        self.train_x = torch.from_numpy(train_xy[:,1:])\n",
    "        self.train_y = torch.from_numpy(train_xy[:,0]).long()\n",
    "        self.n_samples = train_xy.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        x = self.train_x[index].view(1, 28, 28)\n",
    "        y = self.train_y[index]\n",
    "        return x, y\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "class test_MnistDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        #data loading\n",
    "        train_x = np.loadtxt('C:/Users/Marcel/Documents/PyTorch/kaggle/digit_recognizer/test.csv', delimiter=',',dtype=np.float32, skiprows=1) \n",
    "        self.train_x = torch.from_numpy(train_x)\n",
    "        self.n_samples = train_x.shape[0]\n",
    "    def __getitem__(self,index):\n",
    "        x = self.train_x[index].view(1, 28, 28)\n",
    "        return x\n",
    "        \n",
    "    def __len__(self):\n",
    "        #len(dataset)\n",
    "        return self.n_samples\n",
    "    \n",
    "dataset = train_MnistDataset()\n",
    "dataset_test = test_MnistDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdata.datapipes.iter as pipes\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "#Training performance\n",
    "train_size, test_size = int(len(dataset) * 0.8), len(dataset) - (int(len(dataset) * 0.8))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "batch_train, batch_test =  100, 100\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_train, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_test)\n",
    "\n",
    "\n",
    "# Used for submition \n",
    "kaggle_train_dataloader = DataLoader(dataset, batch_size= batch_train, shuffle=True)\n",
    "kaggle_test_dataloader = DataLoader(dataset_test, batch_size= len(dataset_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,64, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3,padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 128,kernel_size=3,padding=1)\n",
    "        self.conv5 = nn.Conv2d(128, 192,kernel_size=3,padding=1)\n",
    "        self.conv6 = nn.Conv2d(192, 192 ,kernel_size=5,padding=2)\n",
    "\n",
    "\n",
    "\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(256,10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv5(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv6(x)\n",
    "        x = F.relu(x) \n",
    "        x = F.max_pool2d(x,2, padding=1)\n",
    "        x = x.flatten(1)   \n",
    "        if self.fc1 is None:\n",
    "            self.fc1 = nn.Linear(x.shape[1], 256)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(layer_in):\n",
    "    if isinstance(layer_in, nn.Linear):\n",
    "        nn.init.kaiming_uniform_(layer_in.weight)\n",
    "        layer_in.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "model.apply(weights_init)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, dataloader):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Store resultsn   n  \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{}]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(dataset), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kaggle used as flag to remove statistics\n",
    "def test(dataloader, predictions = None):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        if predictions == None:\n",
    "            for data, target in dataloader:\n",
    "                output = model(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                test_loss += F.nll_loss(output, target, reduction = 'sum').item()\n",
    "                correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "        else:       \n",
    "            for data in dataloader:\n",
    "                output = model(data)\n",
    "                pred = output.data.max(1, keepdim=True)[1]\n",
    "                predictions.append(pred)\n",
    "                \n",
    "    test_loss /= len(test_dataloader.dataset)\n",
    "    if predictions == None:\n",
    "        print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "            test_loss, correct, len(dataloader.dataset),\n",
    "            100. * correct / len(dataloader.dataset)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3760, Accuracy: 611/8400 (7%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/42000]\tLoss: 2.490115\n",
      "Train Epoch: 1 [10000/42000]\tLoss: 0.351735\n",
      "Train Epoch: 1 [20000/42000]\tLoss: 0.195844\n",
      "Train Epoch: 1 [30000/42000]\tLoss: 0.178433\n",
      "Train Epoch: 1 [40000/42000]\tLoss: 0.264537\n",
      "\n",
      "Test set: Avg. loss: 0.1055, Accuracy: 8117/8400 (97%)\n",
      "\n",
      "Train Epoch: 2 [0/42000]\tLoss: 0.075308\n",
      "Train Epoch: 2 [10000/42000]\tLoss: 0.069986\n",
      "Train Epoch: 2 [20000/42000]\tLoss: 0.231017\n",
      "Train Epoch: 2 [30000/42000]\tLoss: 0.069529\n",
      "Train Epoch: 2 [40000/42000]\tLoss: 0.019222\n",
      "\n",
      "Test set: Avg. loss: 0.0972, Accuracy: 8160/8400 (97%)\n",
      "\n",
      "Train Epoch: 3 [0/42000]\tLoss: 0.029685\n",
      "Train Epoch: 3 [10000/42000]\tLoss: 0.128521\n",
      "Train Epoch: 3 [20000/42000]\tLoss: 0.061205\n",
      "Train Epoch: 3 [30000/42000]\tLoss: 0.072604\n",
      "Train Epoch: 3 [40000/42000]\tLoss: 0.112005\n",
      "\n",
      "Test set: Avg. loss: 0.0729, Accuracy: 8206/8400 (98%)\n",
      "\n",
      "Train Epoch: 4 [0/42000]\tLoss: 0.118604\n",
      "Train Epoch: 4 [10000/42000]\tLoss: 0.089518\n",
      "Train Epoch: 4 [20000/42000]\tLoss: 0.068393\n",
      "Train Epoch: 4 [30000/42000]\tLoss: 0.130693\n",
      "Train Epoch: 4 [40000/42000]\tLoss: 0.049217\n",
      "\n",
      "Test set: Avg. loss: 0.0845, Accuracy: 8181/8400 (97%)\n",
      "\n",
      "Train Epoch: 5 [0/42000]\tLoss: 0.079287\n",
      "Train Epoch: 5 [10000/42000]\tLoss: 0.028859\n",
      "Train Epoch: 5 [20000/42000]\tLoss: 0.200074\n",
      "Train Epoch: 5 [30000/42000]\tLoss: 0.095046\n",
      "Train Epoch: 5 [40000/42000]\tLoss: 0.109043\n",
      "\n",
      "Test set: Avg. loss: 0.0660, Accuracy: 8225/8400 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n_epochs = 5\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "  train(epoch, kaggle_train_dataloader)\n",
    "  # testing on the same data to get more info in the model\n",
    "  test(test_dataloader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "test(kaggle_test_dataloader,predictions)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "predictions = np.array(predictions).reshape(-1)\n",
    "indexes = range(1,len(predictions)+1,1)\n",
    "df = pd.DataFrame({'ImageId': indexes, 'Label': predictions} )\n",
    "df.to_csv('kaggle_sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
